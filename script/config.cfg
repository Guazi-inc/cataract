[cataract]
# hbase environment. For local test, just comment them. 
# --partition
partition=2

# union the result or not, if has multiple sql
# --union
union=false

# number of partitions to save for every sql
# --save-partition
save_partition=1

# set partition
# -t
time=2016100908

# hdfs partition path
car_clues=/user/hive/external/bi/vehicle_c2c_car_clues_hdfs/
car_source=/user/hive/external/bi/vehicle_c2c_car_source_hdfs/
appoint_task=/user/hive/external/bi/vehicle_c2c_appoint_task_hdfs/
contract=/user/hive/external/bi/vehicle_c2c_contract_hdfs/

[spark]
# cataract Main class default
class=com.guazi.cataract.Cataract

# cataract jar, given default
# --jar
jar=~/pc/cataract-0.0.1-SNAPSHOT-jar-with-dependencies.jar

# deploy mode: local yarn
master=yarn

# --deploy-mode 
deploy-mode=cluster

# job name
name=cataract-test

# --executor-cores, no more than 5
# --executor-cores
executor-cores=3

# --executor-memory
# --executor-memory
executor-memory=5g

# --num-executors
num-executors=5

# --driver-memory
driver-memory=6g

[files]
# upload file dependencies
# -j
json=clue_info.json

# default
hivefile=$SPARK_HOME/conf/hive-site.xml

[jars]
